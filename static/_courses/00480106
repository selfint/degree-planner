{"code":"00480106","about":"  Non-convex Optimization: Finding stationary point, ,solving Quasi- convex optimization problems, tensor decomposition and its use in latent variable models. Minimax problems: minimax problems in ML and statistics ,primal-dual and Mirror-Prox methods, sublinear methods using minimax approach, primal-dual methods for robust statistics and ML. Distributed Learning: synchronous and asynchronous methods for centralized problems, synchronous and asynchronous methods for de-centralized problems.    Learning Outcomes: \t At the end of the course the students will be able to: 1. Know advanced techniques in optimization, and to read and understand related papers. 2. Know and understand different considerations in designing complex ML systems. 3. Use advanced code techniques and tools to solve practical optimization problems. 4. Design and analyze optimization methods using the tools that we will study.","points":2,"name":"שיטות אופטימיזציה מתקדמות ללמידה","connections":{"dependencies":[["00460197","00460195"]],"adjacent":[],"exclusive":[]},"seasons":["Winter","Spring","Summer"],"faculty":"הפקולטה להנדסת חשמל ומחשבים","current":false}